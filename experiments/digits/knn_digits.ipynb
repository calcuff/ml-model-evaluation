{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2c63e0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Dynamically add the src/ folder to sys.path\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\", \"..\"))\n",
    "src_path = os.path.join(project_root, \"src\")\n",
    "sys.path.append(src_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97399898",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributes: [ 0.  0.  0.  0.  7.  6.  0.  0.  0.  0.  0.  6. 15.  6.  0.  0.  0.  0.\n",
      "  1. 15.  5. 14.  3.  0.  0.  0. 12.  8.  4. 16.  0.  0.  0.  5. 16.  9.\n",
      " 10. 16.  4.  0.  0.  1. 11. 12. 14. 14.  4.  0.  0.  0.  0.  0.  8.  8.\n",
      "  0.  0.  0.  0.  0.  0. 11.  7.  0.  0.]\n",
      "Class: 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tom/.local/lib/python3.10/site-packages/matplotlib/projections/__init__.py:63: UserWarning: Unable to import Axes3D. This may be due to multiple versions of Matplotlib being installed (e.g. as a system package and as a pip package). As a result, the 3D projection is not available.\n",
      "  warnings.warn(\"Unable to import Axes3D. This may be due to multiple versions of \"\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load digits dataset\n",
    "digits = datasets.load_digits(return_X_y=True)\n",
    "digits_dataset_X = digits[0]\n",
    "digits_dataset_y = digits[1]\n",
    "N = len(digits_dataset_X)\n",
    "\n",
    "# Print the 64 attributes of a random digit, its class, and show the digit\n",
    "digit_to_show = np.random.choice(range(N), 1)[0]\n",
    "print(\"Attributes:\", digits_dataset_X[digit_to_show])\n",
    "print(\"Class:\", digits_dataset_y[digit_to_show])\n",
    "\n",
    "plt.imshow(np.reshape(digits_dataset_X[digit_to_show], (8, 8)), cmap='gray')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c2b2c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.utils import *\n",
    "\n",
    "# Build stratified folds\n",
    "NUM_FOLDS = 10\n",
    "X_train, X_test, y_train, y_test = shuffle_and_split(digits_dataset_X, digits_dataset_y)\n",
    "X_train_folds, y_train_folds = stratified_folds(X_train, y_train, NUM_FOLDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c8254307",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K 1 fold 1 Accuracy 0.98 F1 0.91\n",
      "K 1 fold 2 Accuracy 0.99 F1 0.94\n",
      "K 1 fold 3 Accuracy 1.00 F1 1.00\n",
      "K 1 fold 4 Accuracy 0.99 F1 0.97\n",
      "K 1 fold 5 Accuracy 0.99 F1 0.97\n",
      "K 1 fold 6 Accuracy 0.99 F1 0.97\n",
      "K 1 fold 7 Accuracy 1.00 F1 1.00\n",
      "K 1 fold 8 Accuracy 0.97 F1 0.88\n",
      "K 1 fold 9 Accuracy 0.99 F1 0.97\n",
      "K 1 fold 10 Accuracy 0.99 F1 0.97\n",
      "K 3 fold 1 Accuracy 0.99 F1 0.94\n",
      "K 3 fold 2 Accuracy 0.99 F1 0.94\n",
      "K 3 fold 3 Accuracy 1.00 F1 1.00\n",
      "K 3 fold 4 Accuracy 0.99 F1 0.97\n",
      "K 3 fold 5 Accuracy 0.99 F1 0.97\n",
      "K 3 fold 6 Accuracy 0.99 F1 0.97\n",
      "K 3 fold 7 Accuracy 0.99 F1 0.93\n",
      "K 3 fold 8 Accuracy 0.97 F1 0.86\n",
      "K 3 fold 9 Accuracy 0.99 F1 0.97\n",
      "K 3 fold 10 Accuracy 0.99 F1 0.97\n",
      "K 5 fold 1 Accuracy 0.99 F1 0.94\n",
      "K 5 fold 2 Accuracy 0.99 F1 0.94\n",
      "K 5 fold 3 Accuracy 0.99 F1 0.94\n",
      "K 5 fold 4 Accuracy 0.99 F1 0.97\n",
      "K 5 fold 5 Accuracy 0.99 F1 0.97\n",
      "K 5 fold 6 Accuracy 0.99 F1 0.94\n",
      "K 5 fold 7 Accuracy 0.99 F1 0.93\n",
      "K 5 fold 8 Accuracy 0.97 F1 0.86\n",
      "K 5 fold 9 Accuracy 0.99 F1 0.97\n",
      "K 5 fold 10 Accuracy 0.99 F1 0.97\n",
      "K 10 fold 1 Accuracy 0.99 F1 0.94\n",
      "K 10 fold 2 Accuracy 0.99 F1 0.94\n",
      "K 10 fold 3 Accuracy 0.99 F1 0.94\n",
      "K 10 fold 4 Accuracy 0.99 F1 0.97\n",
      "K 10 fold 5 Accuracy 0.98 F1 0.90\n",
      "K 10 fold 6 Accuracy 0.98 F1 0.91\n",
      "K 10 fold 7 Accuracy 0.99 F1 0.93\n",
      "K 10 fold 8 Accuracy 0.96 F1 0.83\n",
      "K 10 fold 9 Accuracy 0.99 F1 0.94\n",
      "K 10 fold 10 Accuracy 0.99 F1 0.97\n",
      "K 20 fold 1 Accuracy 0.98 F1 0.91\n",
      "K 20 fold 2 Accuracy 0.97 F1 0.86\n",
      "K 20 fold 3 Accuracy 0.95 F1 0.81\n",
      "K 20 fold 4 Accuracy 0.99 F1 0.93\n",
      "K 20 fold 5 Accuracy 0.96 F1 0.82\n",
      "K 20 fold 6 Accuracy 0.96 F1 0.83\n",
      "K 20 fold 7 Accuracy 0.99 F1 0.93\n",
      "K 20 fold 8 Accuracy 0.95 F1 0.81\n",
      "K 20 fold 9 Accuracy 0.99 F1 0.94\n",
      "K 20 fold 10 Accuracy 0.99 F1 0.93\n",
      "K 50 fold 1 Accuracy 0.97 F1 0.86\n",
      "K 50 fold 2 Accuracy 0.92 F1 0.70\n",
      "K 50 fold 3 Accuracy 0.94 F1 0.76\n",
      "K 50 fold 4 Accuracy 0.97 F1 0.83\n",
      "K 50 fold 5 Accuracy 0.92 F1 0.67\n",
      "K 50 fold 6 Accuracy 0.95 F1 0.80\n",
      "K 50 fold 7 Accuracy 0.96 F1 0.80\n",
      "K 50 fold 8 Accuracy 0.92 F1 0.71\n",
      "K 50 fold 9 Accuracy 0.97 F1 0.86\n",
      "K 50 fold 10 Accuracy 0.94 F1 0.73\n",
      "Accuracies {1: 0.9902534965034965, 3: 0.988869463869464, 5: 0.986776418026418, 10: 0.9833041958041958, 20: 0.9707604895104895, 50: 0.9450174825174825}\n",
      "F1s [0.8571428571428571, 0.7027027027027029, 0.7567567567567568, 0.8275862068965518, 0.6666666666666667, 0.8, 0.7999999999999999, 0.7142857142857143, 0.8571428571428571, 0.7333333333333334]\n"
     ]
    }
   ],
   "source": [
    "from models.knn.knn import KNN\n",
    "from utils.utils import *\n",
    "\n",
    "k_values = [1, 3, 5, 10, 20, 50]\n",
    "k_accuracies = {}\n",
    "k_f1s = {}\n",
    "for k in k_values:\n",
    "    accuracies = []\n",
    "    f1s = []\n",
    "    for f, fold in enumerate(X_train_folds):\n",
    "        knn = KNN()\n",
    "        \n",
    "        x_train = np.concatenate([X_train_folds[j] for j in range(len(X_train_folds)) if j != f])\n",
    "        y_train = np.concatenate([y_train_folds[j] for j in range(len(y_train_folds)) if j != f])\n",
    "        x_val = X_train_folds[f]\n",
    "        y_val = y_train_folds[f]\n",
    "        \n",
    "        knn.train(x_train, y_train)\n",
    "        y_val_predict = knn.predict(x_val, k=k)\n",
    "        tp, fp, tn, fn = confusion_matrix(y_val_predict, y_val)\n",
    "        val_acc = calc_accuracy(tp, tn, y_val_predict.shape[0])\n",
    "        precision = calc_precision(tp, fp)\n",
    "        recall = calc_recall(tp, fn)\n",
    "        f1 = calc_f1_score(precision, recall)\n",
    "        accuracies.append(val_acc)\n",
    "        f1s.append(f1)\n",
    "        print(\"K\", k, \"fold\", f+1, \"Accuracy\", f\"{val_acc:.2f}\", \"F1\", f\"{f1:.2f}\")\n",
    "    k_accuracies[k] = np.mean(accuracies)\n",
    "    k_f1s[k] = np.mean(f1s)\n",
    "        \n",
    "print(\"Accuracies\", k_accuracies)\n",
    "print(\"F1s\", f1s)\n",
    "#         print(\"K\", k, \"fold\", f+1, \"Accuracy\", f\"{val_acc:.2f}\", \"F1\", f\"{f1:.2f}\")\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
